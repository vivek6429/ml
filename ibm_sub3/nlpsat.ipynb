{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text to speech\n",
    "from gtts import gTTS\n",
    "\n",
    "import os # to play audio\n",
    "mytext=\"Hello world\"\n",
    "language=\"en\"\n",
    "myobj=gTTS(text=mytext,lang=language,slow=False)\n",
    "myobj.save(\"test.mp3\")\n",
    "os.system(\"test.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sample text helooo'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample code to remove noise\n",
    "noise_list=[\"is\",\"a\",\"this\",\"#\",\"...\"]\n",
    "def _remove_noise(input_text):\n",
    "    words=input_text.split()\n",
    "    noise_free_words=[word for word in words if word not in noise_list]\n",
    "    noise_free_text=\" \".join(noise_free_words)\n",
    "    return noise_free_text\n",
    "\n",
    "_remove_noise(\"# this is a sample text helooo this\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  sdksdmklsm *  '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def _remove_regex(input_text, regex_pattern):\n",
    "    urls = re.finditer(regex_pattern, input_text) \n",
    "    for i in urls: \n",
    "        input_text = re.sub(i.group().strip(), '', input_text)\n",
    "    return input_text\n",
    "\n",
    "regex_pattern = \"#[w]*\" \n",
    "\n",
    "_remove_regex(\" # sdksdmklsm * # \",regex_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/victor/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hop'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "lem=WordNetLemmatizer()\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stem=PorterStemmer()\n",
    "word=\"hopping\"\n",
    "lem.lemmatize(word,\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/victor/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/victor/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('geese', 'JJ')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "text = word_tokenize(\"geese\")\n",
    "nltk.pos_tag(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a direct message retweeted tweet'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookup_dict = {'rt':'Retweet', 'dm':'direct message', \"awsm\" : \"awesome\", \"luv\" :\"love\"}\n",
    "\n",
    "def _lookup_words(input_text):\n",
    "    words = input_text.split() \n",
    "    new_words = [] \n",
    "#     print(words)\n",
    "    for word in words:\n",
    "#         print(word)\n",
    "        if word.lower() in lookup_dict:\n",
    "            word = lookup_dict[word.lower()]\n",
    "        new_words.append(word) \n",
    "#         print(word)\n",
    "        new_text = \" \".join(new_words) \n",
    "#         print(new_text)\n",
    "    return new_text\n",
    "\n",
    "_lookup_words(\"this is a dm retweeted tweet\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Python Program to search string in text usin Tkinter \n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "root = Tk() \n",
    "fram = Frame(root) \n",
    "Label(fram,text='Text to find:').pack(side=LEFT) \n",
    "edit = Entry(fram) \n",
    "edit.pack(side=LEFT, fill=BOTH, expand=1) \n",
    "edit.focus_set() \n",
    "butt = Button(fram, text='Find') \n",
    "butt.pack(side=RIGHT) \n",
    "fram.pack(side=TOP) \n",
    "\n",
    "\n",
    "text = Text(root) \n",
    "text.insert('1.0','''Type your text here''') \n",
    "text.pack(side=BOTTOM) \n",
    "\n",
    "\n",
    "\n",
    "def find(): \n",
    "\t\n",
    "\ttext.tag_remove('found', '1.0', END) \n",
    "\ts = edit.get() \n",
    "\tif s: \n",
    "\t\tidx = '1.0'\n",
    "\t\twhile 1: \n",
    "\t\t\tidx = text.search(s, idx, nocase=1, \n",
    "\t\t\t\t\t\t\tstopindex=END) \n",
    "\t\t\tif not idx: break\n",
    "\t\t\tlastidx = '%s+%dc' % (idx, len(s)) \n",
    "\t\t\ttext.tag_add('found', idx, lastidx) \n",
    "\t\t\tidx = lastidx \n",
    "\ttext.tag_config('found', foreground='red') \n",
    "\tedit.focus_set() \n",
    "butt.config(command=find) \n",
    "root.mainloop() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Program to search string in text usin Tkinter \n",
    "\n",
    "from tkinter import *\n",
    "\n",
    "root = Tk() \n",
    "fram = Frame(root) \n",
    "Label(fram,text='Text to find:').pack(side=LEFT) \n",
    "edit = Entry(fram) \n",
    "edit.pack(side=LEFT, fill=BOTH, expand=1) \n",
    "edit.focus_set() \n",
    "butt = Button(fram, text='Find') \n",
    "butt.pack(side=RIGHT) \n",
    "fram.pack(side=TOP) \n",
    "\n",
    "\n",
    "text = Text(root) \n",
    "text.insert('1.0','''Type your text here''') \n",
    "text.pack(side=BOTTOM) \n",
    "\n",
    "\n",
    "\n",
    "def find(): \n",
    "\t\n",
    "\ttext.tag_remove('found', '1.0', END) \n",
    "\ts = edit.get() \n",
    "\tif s: \n",
    "\t\tidx = '1.0'\n",
    "\t\twhile 1: \n",
    "\t\t\tidx = text.search(s, idx, nocase=1, \n",
    "\t\t\t\t\t\t\tstopindex=END) \n",
    "\t\t\tif not idx: break\n",
    "\t\t\tlastidx = '%s+%dc' % (idx, len(s)) \n",
    "\t\t\ttext.tag_add('found', idx, lastidx) \n",
    "\t\t\tidx = lastidx \n",
    "\ttext.tag_config('found', foreground='red') \n",
    "\tedit.focus_set() \n",
    "butt.config(command=find) \n",
    "root.mainloop() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d1b459ecb9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mhello\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hello\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"world\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[1;32m    959\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1104\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1107\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf\n",
    "hello=tf.strings.join([\"Hello\",\"world\"])\n",
    "sess = tf.compat.v1.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/victor/.local/lib/python3.8/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "484\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "x = tf.constant(11)\n",
    "y = tf.constant(22)\n",
    "result1 = tf.cond(x > y, lambda: tf.add(x, y), lambda: tf.square(y))\n",
    "result2 = tf.cond(x < y, lambda: tf.add(x, y), lambda: tf.square(y))\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess=tf.Session()\n",
    "with sess:\n",
    "\tsess.run(init_op)\n",
    "\tprint(sess.run(result1))\n",
    "\tprint(sess.run(result2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
